{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Notebook\n",
    "This jupyter notebook is used to get predictions from our trained model for images from test set\n",
    "\n",
    "1. Retrieve predictions from inference model\n",
    "2. (Opt.) Visualize predictions\n",
    "3. Merge individual json files with annotations into the one follows COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os import walk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.dataset import ChronsiteTestDataset\n",
    "from utils.configs import ChronsiteConfig\n",
    "\n",
    "import mrcnn.model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directories\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Directory of images to run detection on\n",
    "INFERENCE_DIR = os.path.join(ROOT_DIR, \"test_images\")\n",
    "assert os.path.exists(INFERENCE_DIR), \"You must create this directory manually and upload test images within\"\n",
    "    \n",
    "# Checkpoint of trained model to reload\n",
    "MODEL_BRANCH = \"chronsite20201003T1222\"\n",
    "CHECKPOINT_EPOCH = 77\n",
    "\n",
    "# Directory to store all individual json files\n",
    "INFERENCE_JSON_DIR = os.path.join(INFERENCE_DIR, \"annotation\")\n",
    "if not os.path.exists(INFERENCE_JSON_DIR):\n",
    "    os.mkdir(INFERENCE_JSON_DIR)\n",
    "    \n",
    "# Directory to store all visualizations of predictions\n",
    "INFERENCE_RENDER_DIR = os.path.join(INFERENCE_DIR, \"render\")\n",
    "if not os.path.exists(INFERENCE_RENDER_DIR):\n",
    "    os.mkdir(INFERENCE_RENDER_DIR)\n",
    "    \n",
    "# Final path of json file in coco format\n",
    "FINAL_JSON_PATH = './annotations_group8.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Retrieve predictions from inference model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Test set was distributed via direct file transfer.</font> </br>\n",
    "<font color='red'> You must upload images to INFERENCE_DIR first.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test set: 100\n"
     ]
    }
   ],
   "source": [
    "# Get the list of samples in the test set,\n",
    "# since the test set was retrieved by direct file transfer.\n",
    "sample_ids = []\n",
    "for (dirpath, dirnames, filenames) in walk(INFERENCE_DIR):\n",
    "    if dirpath == INFERENCE_DIR:\n",
    "        for filename in filenames:\n",
    "            sample_ids.append(filename[:-4])\n",
    "print(f\"Number of samples in test set: {len(sample_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 47.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset object for test set\n",
    "dataset_inference = ChronsiteTestDataset(INFERENCE_DIR, sample_ids)\n",
    "dataset_inference.load_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset config for model in inference mode\n",
    "config = ChronsiteConfig()\n",
    "config.IMAGE_RESIZE_MODE = \"pad64\"\n",
    "config.IMAGE_MIN_DIM = None\n",
    "config.IMAGE_MIN_SCALE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/eleven/test_w_submodule/maskrcnn/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jovyan/eleven/test_w_submodule/maskrcnn/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/jovyan/eleven/test_w_submodule/maskrcnn/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/eleven/test_w_submodule/maskrcnn/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/eleven/test_w_submodule/maskrcnn/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Loading weights from  /home/jovyan/eleven/test_w_submodule/maskrcnn/logs/chronsite20201003T1222/mask_rcnn_chronsite_0077.h5\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Re-starting from epoch 77\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                          config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, MODEL_BRANCH,\\\n",
    "                          f\"mask_rcnn_chronsite_{CHECKPOINT_EPOCH:04d}.h5\")\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:42<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve predictions and stored in individual json files\n",
    "for image_id in tqdm(dataset_inference.image_ids):\n",
    "    retrieve_inference_to_json(model, dataset_inference, image_id, INFERENCE_JSON_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(Opt.) Visualize predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the rendered and saved pictures in INFERENCE_RENDER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_id in tqdm(dataset_inference.image_ids):\n",
    "    sample_id = dataset_inference.image_info[image_id]['id']\n",
    "    visualize_inference_sample(sample_id, dataset_inference.class_names_preset,\n",
    "                              INFERENCE_DIR, INFERENCE_JSON_DIR, INFERENCE_RENDER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge individual json files with annotations into the one follows COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_coco_format(sample_ids, INFERENCE_JSON_DIR,\n",
    "                 FINAL_JSON_PATH, dataset_inference.class_names_preset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALSSES 5 classes:\n",
      "{0: 'BG', 1: 'Concrete_pump_hose', 2: 'Mixer_truck', 3: 'People', 4: 'Vertical_formwork'}\n",
      " \n",
      "INFO: {'description': 'Chronsite test set, Group 8.', 'year': 2020}\n",
      " \n",
      "LICENSES: []\n",
      " \n",
      "IMAGES\n",
      "Shapes: {(1080, 1920), (720, 1280), (1024, 1280)}\n",
      "Filenames: ['img/frame527.jpg', 'img/2020-07-15-11-49-12.jpg', 'img/frame516.jpg', 'img/2020-07-15-11-56-11.jpg', 'img/frame528.jpg', 'img/frame1628.jpg', 'img/frame521.jpg', 'img/2019-10-17-14-06-24.jpg', 'img/frame510.jpg', 'img/frame0519.jpg', 'img/2019-10-17-14-30-46.jpg', 'img/2019-10-17-14-42-56.jpg', 'img/frame1620.jpg', 'img/2020-07-27-09-54-07.jpg', 'img/frame0509.jpg', 'img/2020-08-13-19-13-58.jpg', 'img/2019-10-17-13-42-19.jpg', 'img/frame515.jpg', 'img/2019-10-17-14-55-14.jpg', 'img/frame0489.jpg', 'img/frame0504.jpg', 'img/2020-07-15-11-36-02.jpg', 'img/frame968.jpg', 'img/2020-07-15-12-01-36.jpg', 'img/2020-07-27-13-29-02.jpg', 'img/frame524.jpg', 'img/frame1624.jpg', 'img/frame0464.jpg', 'img/frame0479.jpg', 'img/2020-07-15-11-55-24.jpg', 'img/2020-07-15-11-23-38.jpg', 'img/frame0494.jpg', 'img/frame0449.jpg', 'img/2020-08-13-19-44-13.jpg', 'img/2020-07-27-14-06-07.jpg', 'img/frame519.jpg', 'img/frame514.jpg', 'img/frame960.jpg', 'img/frame1581.jpg', 'img/2020-08-13-18-30-05.jpg', 'img/frame1631.jpg', 'img/frame955.jpg', 'img/2020-08-13-18-50-31.jpg', 'img/2020-07-27-11-46-06.jpg', 'img/2020-07-27-14-07-38.jpg', 'img/2020-08-13-18-33-52.jpg', 'img/2020-07-27-14-25-48.jpg', 'img/frame518.jpg', 'img/frame951.jpg', 'img/2020-08-13-19-04-08.jpg', 'img/2020-07-27-11-49-08.jpg', 'img/frame962.jpg', 'img/2020-07-15-11-51-32.jpg', 'img/frame529.jpg', 'img/frame517.jpg', 'img/frame966.jpg', 'img/2020-07-27-11-47-37.jpg', 'img/frame0499.jpg', 'img/frame522.jpg', 'img/frame1596.jpg', 'img/2020-07-27-11-46-52.jpg', 'img/frame1606.jpg', 'img/2019-10-17-14-18-46.jpg', 'img/frame953.jpg', 'img/2020-08-13-18-39-10.jpg', 'img/frame512.jpg', 'img/frame523.jpg', 'img/frame0459.jpg', 'img/frame520.jpg', 'img/frame957.jpg', 'img/frame1602.jpg', 'img/2020-08-13-19-16-59.jpg', 'img/2020-07-15-11-33-43.jpg', 'img/2020-08-13-20-43-15.jpg', 'img/2020-07-27-09-14-46.jpg', 'img/frame964.jpg', 'img/frame0474.jpg', 'img/frame1578.jpg', 'img/frame1592.jpg', 'img/frame1585.jpg', 'img/frame944.jpg', 'img/frame1589.jpg', 'img/frame1613.jpg', 'img/2019-10-17-15-07-15.jpg', 'img/2020-08-13-18-30-50.jpg', 'img/frame525.jpg', 'img/frame526.jpg', 'img/frame0484.jpg', 'img/2019-10-17-13-30-11.jpg', 'img/frame959.jpg', 'img/frame946.jpg', 'img/frame0454.jpg', 'img/frame0514.jpg', 'img/2019-10-17-13-54-13.jpg', 'img/frame948.jpg', 'img/2020-07-15-11-46-06.jpg', 'img/frame0469.jpg', 'img/2019-10-17-15-19-05.jpg', 'img/2020-07-15-11-53-05.jpg', 'img/frame1617.jpg']\n",
      "ID: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99}\n",
      " \n",
      "SEGMENTATIONS\n",
      "number of annotations 995\n"
     ]
    }
   ],
   "source": [
    "# New json in coco format will be verified if there is no exception or assert triggered.\n",
    "verify_coco_json(FINAL_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
